{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47d2b14f-d6e8-4e4f-ae13-cef43e61a3b6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Theoretical Foundations of Computer Science II COMP2870\n",
    "\n",
    "**School of Computer Science, University of Leeds**\n",
    "\n",
    "# Lab05: Improving QR factorisation\n",
    "\n",
    "These labsheets contains *formative activities* (which contribute to your learning) and *summative activities* (which you will complete and submit to be assessed as part of your portfolio).\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Portfolio exercise</b>\n",
    "\n",
    "Exercise marked with a red box is a summative exercise and must be submitted as part of your portfolio. You should use Gradescope to submit portfolio activities.\n",
    "</div>\n",
    "\n",
    "### Expectations\n",
    "\n",
    "1. **Timeliness** You should complete all of the activities in the order provided and submit your portfolio evidence on Gradescope before the completion date (Friday 28 November, 5pm).\n",
    "\n",
    "2. **Presentation** You should present all of your work clearly and concisely following additional guidance below.\n",
    "\n",
    "3. **Integrity** You are responsible for ensuring that all the evidence you submit as part of your portfolio is entirely your own work. You can find out more about Academic integrity on the Skill@library website. All work you submit for assessment is subject to the academic integrity policy.\n",
    "\n",
    "### Feedback\n",
    "Feedback on formative activities will be provided via lab classess and tutorials. Feedback on evidence submitted as part of the portfolio will be available on Gradescope.\n",
    "\n",
    "### Support opportunities\n",
    "Support with the activity sheet is available in the lab classes and tutorials. Individual support is available via the online booking system.\n",
    "\n",
    "### Statement on the Use of Generative AI (Red Category)\n",
    "This assessment is RED according to the GenAI traffice light system. **Generative AI (GenAI) tools cannot be used**. The aim of this task is for you to develop and demonstrate the specific skills and knowledge covered in the taught sessions. We want you to independently develop your understanding, criticical thinking skills and demonstrate fundamental skills that will be required throughout your programme. Reliance on GenAI could prevent you from achieving the intended learning outcomes and may impeded your skill development.\n",
    "\n",
    "You are still permitted to use dictionaries, thesauri, spelling and grammer-checking software to help identify and correct spelling mistakes and grammatrical errors (even if they are powered by GenAI). However, you should not use any software to rewrite sentence or make substantial changes to your original text, as this would be against the rules of this category.\n",
    "\n",
    "Failure to comply with these requirements may be considered academic misconduct under University regulations.\n",
    "\n",
    "### Expected time for completion:\n",
    "1-2 hours\n",
    "\n",
    "### Expected completion date:\n",
    "Friday 28 November, 5pm\n",
    "\n",
    "## Coursework summary\n",
    "\n",
    "These lab exercises cover the QR algorithm.\n",
    "\n",
    "## Learning outcomes\n",
    "\n",
    "On completion of this activity sheet you will have demonstrated that you can:\n",
    "\n",
    "- explain practical challenges working with floating-point numbers\n",
    "- apply algorithms to compute eigenvectors and eigenvalues of large matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82429de1-cff7-4b1d-896c-a67f4f1cbc9a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "header"
    ]
   },
   "source": [
    "## How to access the lab\n",
    "\n",
    "You can access the lab worksheet directly through [minerva](https://minerva.leeds.ac.uk/), [github](https://github.com/COMP2870-2526/linear-algebra-student-labs) or using Noteable (accessible via Minerva - see `README.md` for detailed instructions).\n",
    "\n",
    "These lab worksheets are written using ['Jupyter Notebooks'](https://jupyter.org/). Many, many tutorials and guides are [available online](https://www.dataquest.io/blog/jupyter-notebook-tutorial/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dde3cb-aaa1-4e14-ad9d-a2965243faca",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "portfolio"
    ]
   },
   "source": [
    "## Exercise 1: Problems with QR factorisation\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Portfolio exercise</b>\n",
    "You should submit:\n",
    "\n",
    "1. The tables of results.\n",
    "2. Your explanation of the results.\n",
    "</div>\n",
    "\n",
    "The Gram-Schmidt process is known to not be numerically stable. In practice, this means that the method can have problems which lead to loss of orthogonality through the process. In this exercise, we will explore this problem on a simple $2 \\times 2$ problem.\n",
    "\n",
    "For $\\varepsilon > 0$, let $A_\\varepsilon$ be the matrix given by\n",
    "$$\n",
    "A_\\varepsilon = \\begin{pmatrix}\n",
    "1 & 1 + \\varepsilon \\\\\n",
    "1 + \\varepsilon & 1\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "There are three ways to judge the accuracy of a QR factorisation\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{error}_1 &= \\| A - QR \\|_2 \\\\\n",
    "\\text{error}_2 &= \\| Q^T Q - I_{n} \\|_2 \\\\\n",
    "\\text{error}_3 &= \\| R - \\text{toupper}(R) \\|_2,\n",
    "\\end{aligned}\n",
    "$$\n",
    "where $\\| . \\|_2$ is a norm on matrices than can be computed using `np.linalg.norm(...)` and $\\text{toupper}$ is a function that takes a matrix to only its upper trianglar part which can be computer using `np.triu(...)`.\n",
    "\n",
    "1. Create a table with the columns $\\varepsilon$, $\\text{error}_1$, $\\text{error}_2$ and $\\text{error}_3$ for $\\varepsilon = 10^{-6}, 10^{-7}, \\ldots, 10^{-16}$ using the classical Gram-Scmidt process from the lectures.\n",
    "2. Explain in detail why you see the results are not as good as you would like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6790ac53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     epsilon            err1            err2            err3\n",
      "     1.0e-06    1.110223e-16    1.002116e-10    0.000000e+00\n",
      "     1.0e-07    0.000000e+00    1.625373e-09    0.000000e+00\n",
      "     1.0e-08    0.000000e+00    1.720446e-08    0.000000e+00\n",
      "     1.0e-09    0.000000e+00    2.215446e-07    0.000000e+00\n",
      "     1.0e-10    0.000000e+00    5.000008e-11    0.000000e+00\n",
      "     1.0e-11    0.000000e+00    5.000159e-12    0.000000e+00\n",
      "     1.0e-12    0.000000e+00    2.220249e-04    0.000000e+00\n",
      "     1.0e-13    0.000000e+00    1.109877e-03    0.000000e+00\n",
      "     1.0e-14    0.000000e+00    2.221674e-02    0.000000e+00\n",
      "     1.0e-15    0.000000e+00    6.803858e-16    0.000000e+00\n",
      "     1.0e-16    0.000000e+00    1.000000e+00    0.000000e+00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def classical_gram_schmidt(A):\n",
    "    \"\"\"Return Q, R using classical Gramâ€“Schmidt.\"\"\"\n",
    "    m, n = A.shape\n",
    "    Q = np.zeros((m, n))\n",
    "    R = np.zeros((n, n))\n",
    "\n",
    "    for j in range(n):\n",
    "        v = A[:, j].copy()\n",
    "        for i in range(j):\n",
    "            R[i, j] = np.dot(Q[:, i], A[:, j])\n",
    "            v = v - R[i, j] * Q[:, i]\n",
    "        R[j, j] = np.linalg.norm(v)\n",
    "        Q[:, j] = v / R[j, j]\n",
    "    return Q, R\n",
    "\n",
    "\n",
    "def t_upper(R):\n",
    "    \"\"\"Upper triangular part of R.\"\"\"\n",
    "    return np.triu(R)\n",
    "\n",
    "\n",
    "epsilons = [10**(-k) for k in range(6, 17)]\n",
    "print(f\"{'epsilon':>12} {'err1':>15} {'err2':>15} {'err3':>15}\")\n",
    "\n",
    "for eps in epsilons:\n",
    "    A = np.array([[1, 1+eps],\n",
    "                  [1+eps, 1]], float)\n",
    "\n",
    "    Q, R = classical_gram_schmidt(A)\n",
    "\n",
    "    err1 = np.linalg.norm(A - Q @ R, 2)          # reconstruction error\n",
    "    err2 = np.linalg.norm(Q.T @ Q - np.eye(2),2) # loss of orthogonality\n",
    "    err3 = np.linalg.norm(R - t_upper(R),2)       # failure to be upper-triangular\n",
    "\n",
    "    print(f\"{eps:12.1e} {err1:15.6e} {err2:15.6e} {err3:15.6e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2930ee61-5586-4831-9c7c-1f205fe5e52d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "formative"
    ]
   },
   "source": [
    "## Exercise 2: Improving the QR with Gram Schmidt approach\n",
    "\n",
    "In this exercise, we will improve our implementation of\n",
    "`gram_schmidt_eigen`.\n",
    "\n",
    "Implement *one* of the following improvements and see how the change the\n",
    "resulting performance of the algorithm in terms of robustness, accuracy\n",
    "and/or efficiency.\n",
    "\n",
    "1.  Following [Example\n",
    "    7.3](https://comp2870-2526.github.io/linear-algebra-notes/src/lec07.html#exm-char),\n",
    "    we have a good formula for how *shifting* a matrix changes the\n",
    "    eigenvalues and eigenvectors of a matrix.\n",
    "\n",
    "    For a shift value $\\mu$, the key idea for the shifted algorithm is\n",
    "    to shift the matrix before computing QR factorisation\n",
    "    $$\n",
    "    A - \\mu I_n = QR,\n",
    "    $$ and then undo the shift when updating\n",
    "    $$\n",
    "    A^{\\text{new}} = RQ + \\mu I_n.\n",
    "    $$\n",
    "\n",
    "    There are two suggestions form the literature to improve the speed\n",
    "    of convergence.\n",
    "\n",
    "    -   The first is to take the bottom right value of the matrix $A$ at\n",
    "        each step $\\mu = A_{nn}$. Note this value changes throughout the\n",
    "        computation as we update $A$ in-place.\n",
    "    -   The second is to use the *Wilkinson shift*. In this case, we\n",
    "        compute the eigenvalues of the bottom-right $2 \\times 2$\n",
    "        submatrix of $A$ (using your code from Lab04) and then\n",
    "        choose the eigenvalue closest to the bottom-right element of $A$\n",
    "        as our value of $\\mu$.\n",
    "\n",
    "    Neither change affects how the matrix $V$ should be computed.\n",
    "\n",
    "2.  We can also scale the matrix to be close to unit size. We again do\n",
    "    this before the QR factorisation and then undo during reconstruction\n",
    "\n",
    "    1.  Set $\\alpha = \\max_{ij} | A_{ij} |$ and\n",
    "        $\\tilde{A} = A / \\alpha$.\n",
    "    2.  Compute the QR factorisation of $\\tilde{A} = QR$.\n",
    "    3.  Update the $A$ as\n",
    "        $$\n",
    "        A^{\\text{new}} = \\alpha RQ\n",
    "        $$\n",
    "\n",
    "    This change does not affect how the matrix $V$ should be computed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b78ae0-9f72-4832-94ca-d26f0b0451ea",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "formative"
    ]
   },
   "source": [
    "Test your solution by finding the eigenvalues and eigenvectors of 10 randomly created symmetric matrices of sizes $n = 2, 4, 8, 16, 32$. Comment on what you find.\n",
    "\n",
    "For the method for the lectures and each approach you implement, make a table of problem size, average (mean) time taken, average QR iterations and maximum error as implemented by the `test_accuracy_of_eigensolve` function.\n",
    "\n",
    "How could you improve the variation of the method further in order to improve the convergence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bbfa112-a3c2-472c-8b3e-000ee96f300c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "formative"
    ]
   },
   "outputs": [],
   "source": [
    "from scipy.stats import special_ortho_group\n",
    "\n",
    "# replicable random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "def random_symmetric_matrix(n):\n",
    "    # generate a random matrix\n",
    "    S = special_ortho_group.rvs(n)\n",
    "    D = np.diag(np.random.randint(1, 10, (n,)) / 2)\n",
    "    A = S.T @ D @ S\n",
    "    return A\n",
    "\n",
    "\n",
    "def test_accuracy_of_eigensolve(A, eigenvalues, eigenvectors):\n",
    "    \"\"\"\n",
    "    test accuracy of solution of eigenvalue problem\n",
    "    \"\"\"\n",
    "    residuals = []\n",
    "    for i in range(len(eigenvalues)):\n",
    "        residual = np.linalg.norm(\n",
    "            A @ eigenvectors[:, i] - eigenvalues[i] * eigenvectors[:, i]\n",
    "        )\n",
    "        residuals.append(residual)\n",
    "    return max(residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05180e89-fd0d-49af-acee-2085acee3a4e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "formative"
    ]
   },
   "source": [
    "If you have time, implement one or more additional updates again\n",
    "comparing using the test cases from the lecture notes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
